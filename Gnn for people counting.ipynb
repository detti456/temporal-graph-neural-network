{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84786121",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fa26e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:37:42.686902500Z",
     "start_time": "2024-05-16T19:37:42.637900800Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import random\n",
    "from typing import Callable, Union, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "from scipy.spatial import distance as distance_calculator\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.nn import GCNConv, global_max_pool, GATConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.typing import PairTensor, OptTensor\n",
    "from torch_geometric.utils import scatter, to_networkx, add_self_loops\n",
    "import seaborn as sn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, Dropout, ReLU, BatchNorm1d as BN\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_multi_head_attention import MultiHeadAttention\n",
    "import torch_scatter\n",
    "from torch_cluster import knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefe0c83114d2e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Showing the difference between the same frame numbers on different days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580317b11c3b4d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:37:43.824430100Z",
     "start_time": "2024-05-16T19:37:43.553498Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "same_frame_1: DataFrame = pd.read_csv(\"data/2/2/Text_01Jun144751.csv104247.0.csv\", header=None, dtype=float)\n",
    "same_frame_2: DataFrame = pd.read_csv(\"data/3/3/Text_05Jun144421.csv104247.0.csv\", header=None, dtype=float)\n",
    "\n",
    "plt.scatter(same_frame_1.to_numpy()[:, 5], same_frame_1.to_numpy()[:, 4], c=\"red\", label='01 Jun')\n",
    "plt.scatter(same_frame_2.to_numpy()[:, 5], same_frame_2.to_numpy()[:, 4], c=\"green\", label='05 Jun')\n",
    "plt.legend()\n",
    "plt.title(\"Same frame numbers on different days\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.xlim(-10, 4)\n",
    "plt.ylim(2, 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddc5c61e30b106",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Loading the data\n",
    "In each files, the frame numbers are shifted to come after the largest frame number in the previous file. This way all frame numbers are unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7b1a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:38:28.263295100Z",
     "start_time": "2024-05-16T19:37:45.133483600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest frame number: 87019891.0\n",
      "Total number of frames: 22209\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "column_names=['range','azimuth','doppler','snr','y','x','current_frame','seq']\n",
    "\n",
    "features0: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/0/0/*.csv\")])\n",
    "features0.insert(8, \"Label\", np.zeros(len(features0), dtype=int), True)\n",
    "max_frame = max(features0[\"current_frame\"])\n",
    "\n",
    "features1: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/1/1/*.csv\")])\n",
    "features1.insert(8, \"Label\", np.ones(len(features1), dtype=int), True)\n",
    "min_frame = min(features1[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features1[\"current_frame\"] += shift\n",
    "max_frame = max(features1[\"current_frame\"])\n",
    "\n",
    "features2: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/2/2/*.csv\")])\n",
    "features2.insert(8, \"Label\", np.full(len(features2), 2, dtype=int), True)\n",
    "min_frame = min(features2[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features2[\"current_frame\"] += shift\n",
    "max_frame = max(features2[\"current_frame\"])\n",
    "\n",
    "features3: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/3/3/*.csv\")])\n",
    "features3.insert(8, \"Label\", np.full(len(features3), 3, dtype=int), True)\n",
    "min_frame = min(features3[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features3[\"current_frame\"] += shift\n",
    "max_frame = max(features3[\"current_frame\"])\n",
    "\n",
    "features4: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/4/4/*.csv\")])\n",
    "features4.insert(8, \"Label\", np.full(len(features4), 4, dtype=int), True)\n",
    "min_frame = min(features4[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features4[\"current_frame\"] += shift\n",
    "max_frame = max(features4[\"current_frame\"])\n",
    "\n",
    "features5: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/bigger/bigger/*.csv\")])\n",
    "features5.insert(8, \"Label\", np.full(len(features5), 5, dtype=int), True)\n",
    "min_frame = min(features5[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features5[\"current_frame\"] += shift\n",
    "max_frame = max(features5[\"current_frame\"])\n",
    "\n",
    "all_data = pd.concat([features0, features1, features2, features3, features4, features5])\n",
    "\n",
    "all_data_grouped = all_data.groupby(\"current_frame\")\n",
    "print(\"Largest frame number: \"+str(max_frame))\n",
    "print(\"Total number of frames: \"+str(len(all_data_grouped)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0003bf13ae2c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Showing the visual interpretation of consequent frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc91187e545248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:05:42.370395900Z",
     "start_time": "2024-05-15T20:05:40.459885500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [frame.to_numpy() for (_, frame) in all_data_grouped]\n",
    "frame_num = 21202\n",
    "frame1 = data[frame_num]\n",
    "frame2 = data[frame_num+1]\n",
    "frame3 = data[frame_num+2]\n",
    "plt.scatter(frame1[:, 5], frame1[:, 4], c=\"red\", label=\"Frame 1\")\n",
    "plt.scatter(frame2[:, 5], frame2[:, 4], c=\"lime\", label=\"Frame 2\")\n",
    "plt.scatter(frame3[:, 5], frame3[:, 4], c=\"blue\", label=\"Frame 3\")\n",
    "plt.legend()\n",
    "plt.title(\"3 consequent frames of 5 people moving\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.xlim(-9, 0)\n",
    "plt.ylim(2, 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59cb43360e9ae26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T15:48:23.352021800Z",
     "start_time": "2024-05-14T15:48:21.854722500Z"
    },
    "collapsed": false
   },
   "source": [
    "#### Generate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc84040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e76f4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16461\n"
     ]
    }
   ],
   "source": [
    "frame_graphs = torch.load(\"data/frame_graphs_k1_no_frame_num.pt\")\n",
    "print(len(frame_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712d2a0447185f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:38:28.273297800Z",
     "start_time": "2024-05-16T19:38:28.267298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def connect_frames(current_frame, previous_frame, k: int, start_index: int):\n",
    "    \"\"\"\n",
    "    Calculates the edges between two frames. \n",
    "    \n",
    "    :param current_frame: The current frame containing parameters to calculate the distance based on \n",
    "    :param previous_frame: The previous frame containing parameters to calculate the distance based on \n",
    "    :param k: The number of nearest neighbours to have in the graph\n",
    "    :param start_index: The index to start labeling the nodes from\n",
    "    :return: The values (distance between points) of the edges and an adjacency list containing the nodes that are connected in the graph\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    adjacency_list = []\n",
    "    previous_nodes = np.arange(len(previous_frame))\n",
    "    for i, point in enumerate(current_frame):\n",
    "        distances = distance_calculator.cdist([point], previous_frame, 'euclidean')[0]\n",
    "        idx = distances.argsort()[::-1]\n",
    "        distances = distances[idx]\n",
    "        previous_nodes = previous_nodes[idx]\n",
    "        neighbours = k\n",
    "        if len(distances) < k:\n",
    "            neighbours = len(distances)\n",
    "        for j in range(neighbours):\n",
    "            edges.append(distances[j])\n",
    "            adjacency_list.append((i+start_index, previous_nodes[j]+start_index+len(current_frame)))\n",
    "    return edges, adjacency_list\n",
    "\n",
    "def create_graph_list(frames:[DataFrame], k = 1, frame_depth = 2):\n",
    "    \"\"\"\n",
    "    Creates a list of Data objects that represents the graphs build from the input data. The edges in the graph connects the frames to the previous frame by connecting each points in a frame to it's nearest neighbour in the previous frame. The nodes contain information about: doppler, snr, y and x. The edges store information about the distance between the points (closer points have higher value).\n",
    "    \n",
    "    :param frames: input data grouped and sorted by the frame number\n",
    "    :param k: the number of nearest neighbours to connect each points to\n",
    "    :param frame_depth: the number of frames, one graph should contain\n",
    "    :return: a list of Data objects, containing information about the created graphs\n",
    "    \"\"\"\n",
    "    graphs = []\n",
    "    for i, frame in enumerate(frames[frame_depth:]):\n",
    "        nodes = []\n",
    "        edges = []\n",
    "        adjacency_list = []\n",
    "        relevant_frames = frames[i: i + frame_depth + 1]\n",
    "        point_data = [rf[['doppler','snr','y','x']] for rf in relevant_frames]\n",
    "        time_distance = relevant_frames[-1].iloc[0, 6] - relevant_frames[0].iloc[0, 6]\n",
    "        if time_distance > frame_depth * 3:\n",
    "            continue\n",
    "        point_data_array = [df.to_numpy() for df in point_data]\n",
    "        start_index = 0\n",
    "        for depth in range(frame_depth):\n",
    "            pairwise_edges, pairwise_adjacency_list = \\\n",
    "                connect_frames(point_data_array[frame_depth-depth], point_data_array[frame_depth-depth-1], k, start_index)\n",
    "            start_index += len(relevant_frames[frame_depth-depth])\n",
    "            # pairwise_edges = pairwise_edges / np.linalg.norm(pairwise_edges)\n",
    "            edges.extend(pairwise_edges)\n",
    "            adjacency_list.extend(pairwise_adjacency_list)\n",
    "            nodes.extend(point_data_array[frame_depth-depth])\n",
    "        nodes.extend(point_data_array[0])\n",
    "        label = frame[\"Label\"].values[0]\n",
    "        # edges = F.softmax(torch.tensor(np.array(edges), dtype=torch.float), dim=0)\n",
    "        \n",
    "        graphs.append(Data(x=torch.tensor(np.array(nodes), dtype=torch.float, device=device), \n",
    "                    edge_index=torch.tensor(np.array(adjacency_list), dtype=torch.int64, device=device).t().contiguous(),\n",
    "                    edge_attr=torch.tensor(np.array(edges), dtype=torch.float, device=device),\n",
    "                    y=torch.tensor(label, dtype=torch.int64, device=device)))\n",
    "    return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb835c190a412b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:42:28.993353700Z",
     "start_time": "2024-05-16T19:38:28.273297800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_array = np.asarray([frame for (_, frame) in all_data_grouped], dtype=\"object\")\n",
    "sorted_data= sorted(data_array,key=lambda x:x[\"current_frame\"].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ce492",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_graphs = create_graph_list(sorted_data)\n",
    "print(len(frame_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb517634c104813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T19:47:52.635759200Z",
     "start_time": "2024-05-14T19:47:52.618763700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(frame_graphs[0][\"edge_attr\"])\n",
    "torch.save(frame_graphs, \"data/frame_graphs_k1_no_frame_num.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923f91c2d2d1855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T11:45:01.201781700Z",
     "start_time": "2024-05-13T11:45:01.063781400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class GraphVisualization:\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.visual = []\n",
    "#         self.nodes = []\n",
    "\n",
    "#     def addEdge(self, a, b, d):\n",
    "#         temp = [a, b, {\"dist\": d}]\n",
    "#         self.visual.append(temp)\n",
    "\n",
    "#     def addNode(self, a):\n",
    "#         self.nodes.append(a)\n",
    "\n",
    "#     def visualize(self):\n",
    "#         gg = nx.Graph()\n",
    "#         gg.add_nodes_from(self.nodes)\n",
    "#         gg.add_edges_from(self.visual)\n",
    "#         nx.draw_networkx(gg)\n",
    "#         plt.show()\n",
    "\n",
    "# G = GraphVisualization()\n",
    "# # for i, _ in enumerate(frame_graphs[0].nodes):\n",
    "# #     G.addNode(i)\n",
    "# for i, adj in enumerate(frame_graphs[0].adjacency_list):\n",
    "#     G.addEdge(adj[0], adj[1], frame_graphs[0].edges[i])\n",
    "\n",
    "# G.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758fa57d7e7c477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T11:45:01.794808500Z",
     "start_time": "2024-05-13T11:45:01.202777600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tiny_array = [t.to_numpy() for t in sorted_data]\n",
    "print(len(tiny_array[0])+len(tiny_array[1])+len(tiny_array[2]))\n",
    "\n",
    "# plt.scatter(tiny_array[0][:, 5], tiny_array[0][:, 4], c='blue')\n",
    "# plt.scatter(tiny_array[1][:, 5], tiny_array[1][:, 4], c='red')\n",
    "plt.scatter(tiny_array[2][:, 5], tiny_array[2][:, 4], c='green')\n",
    "# plt.xlim(-10, 4)\n",
    "# plt.ylim(2, 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e18cb5a58f42f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T11:45:01.838810100Z",
     "start_time": "2024-05-13T11:45:01.798807800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, split='train', transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        if split == 'train':\n",
    "            path = self.processed_paths[0]\n",
    "        elif split == 'validation':\n",
    "            path = self.processed_paths[1]\n",
    "        else:\n",
    "            path = self.processed_paths[2]\n",
    "        self.load(path)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['ply_data_train.h5', 'ply_data_validation.h5', 'ply_data_test.h5']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['ply_data_train.pt', 'ply_data_validation.pt', 'ply_data_test.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])\n",
    "        # For PyG<2.4:\n",
    "        # torch.save(self.collate(data_list), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89727635f494f0c7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853152cf268acc9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T21:35:05.273022700Z",
     "start_time": "2024-05-16T21:35:05.238024700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# frame_graphs = torch.load(\"data/frame_graphs.pt\")\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(frame_graphs)\n",
    "train = frame_graphs[:int(0.7 * len(frame_graphs))]\n",
    "test = frame_graphs[int(0.7 * len(frame_graphs)):int(0.85 * len(frame_graphs))]\n",
    "val = frame_graphs[int(0.85 * len(frame_graphs)):]\n",
    "\n",
    "train_dataloader = DataLoader(train[:1000], batch_size=32, shuffle=True, num_workers = 0) \n",
    "test_dataloader = DataLoader(test[:300], batch_size=32, shuffle=True, num_workers = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e12aebbd58c7d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### The Graph Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aab01bc32c6e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:26:55.500820800Z",
     "start_time": "2024-05-15T20:26:55.471818100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_features, 16)\n",
    "        self.conv2 = GCNConv(16, out_features)\n",
    "        # self.conv3 = GCNConv(16, out_features)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        edge_weight = data.edge_attr\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = scatter(x, data.batch, dim=0, reduce='mean')\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GDPModel(torch.nn.Module):\n",
    "    def __init__(self, num_features=3, hidden_size=32, target_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_features = num_features\n",
    "        self.target_size = target_size\n",
    "        self.conv1 = GATConv(self.num_features, self.hidden_size, edge_dim = 1)\n",
    "        self.conv2 = GATConv(self.hidden_size, self.hidden_size, edge_dim = 1)\n",
    "        # self.linear = nn.Linear(self.hidden_size, self.target_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_attr=edge_attr) # adding edge features here!\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr=edge_attr) # edge features here as well\n",
    "        # x = self.linear(x)\n",
    "        x = scatter(x, data.batch, dim=0, reduce='mean')\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea61281bf4585f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Training the model with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b05e73dcbf69c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:31:23.056708800Z",
     "start_time": "2024-05-15T20:26:56.594163500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_features, 16)\n",
    "        self.conv2 = GCNConv(16, out_features)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        edge_weight = data.edge_attr\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = scatter(x, data.batch, dim=0, reduce='mean')\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN(4,6).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "for epoch in range(50):\n",
    "    for data_batch in train_dataloader:\n",
    "        data_batch = data_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data_batch)\n",
    "        loss = F.nll_loss(out, data_batch.y)\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75002847",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [tensor.cpu() for tensor in losses]\n",
    "\n",
    "plt.plot(losses, c=\"blue\")\n",
    "plt.plot(accuracies, c=\"red\")\n",
    "plt.title(\"Loss of the training\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: \"+str(accuracies[-1]))\n",
    "print(\"Loss: \"+str(losses[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f536d22a8db821b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8e8b71a3264ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:36:47.294359Z",
     "start_time": "2024-05-15T20:36:46.102361300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3633\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_y_pred_label = []\n",
    "total_y_true_label = []\n",
    "correct = 0\n",
    "for test_batch in test_dataloader:\n",
    "    test_batch = test_batch.to(device)\n",
    "    pred = model(test_batch).argmax(dim=1)\n",
    "    total_y_pred_label.extend(pred)\n",
    "    total_y_true_label.extend(test_batch.y)\n",
    "    # print(\"Predicted: \" + str(pred) + \", real: \"+ str(test_batch.y))\n",
    "    correct += (pred == test_batch.y).sum()\n",
    "acc = int(correct) / 300\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a574b145d35f779e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:36:59.453534500Z",
     "start_time": "2024-05-15T20:36:59.198536Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0]\n",
      " [ 1 19 30  4  1 11]\n",
      " [ 0 12 40 13  1 28]\n",
      " [ 0  6 18 14  0 12]\n",
      " [ 0  6  7  3  0 28]\n",
      " [ 0  0  6  4  0 36]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 47.7222222222222, 'Predicated Label')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SHAPE_NAMES = [0,1,2,3,4,5]\n",
    "total_y_pred = [pred_label.item() for pred_label in total_y_pred_label]\n",
    "total_y_true = [true_label.item() for true_label in total_y_true_label]\n",
    "cm = confusion_matrix(total_y_true, total_y_pred, labels=SHAPE_NAMES)\n",
    "print(cm)\n",
    "# cm = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]) * 100\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = SHAPE_NAMES,\n",
    "              columns = SHAPE_NAMES)\n",
    "plt.figure(figsize = (10,7))\n",
    "plot = sn.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "figure = plot.get_figure()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicated Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5275ef1b2d43a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T19:47:18.391553400Z",
     "start_time": "2024-05-14T19:47:18.379553300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_points = np.array([d.y.item() for d in train[:1000]])\n",
    "# zeros = np.where(data_points  == 0)[0]\n",
    "# print(len(zeros))\n",
    "# ones = np.where(data_points  == 1)[0]\n",
    "# print(len(ones))\n",
    "# print(len(np.where(data_points  == 2)[0]))\n",
    "# print(len(np.where(data_points  == 3)[0]))\n",
    "# print(len(np.where(data_points  == 4)[0]))\n",
    "# print(len(np.where(data_points  == 5)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f8f9cfd8d278a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Training with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b92430669b64c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:42:29.061352400Z",
     "start_time": "2024-05-16T19:42:29.001355100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "\n",
    "def reset(nn):\n",
    "    def _reset(item):\n",
    "        if hasattr(item, 'reset_parameters'):\n",
    "            item.reset_parameters()\n",
    "\n",
    "    if nn is not None:\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\n",
    "            for item in nn.children():\n",
    "                _reset(item)\n",
    "        else:\n",
    "            _reset(nn)\n",
    "\n",
    "class GeneralizedTemporalSelfAttentionDynamicEdgeConv(MessagePassing):\n",
    "    def __init__(self, nn: Callable, T: int, attention_in_features: int, head_num: int, k: int,\n",
    "                 aggr: str = 'max',\n",
    "                 num_workers: int = 1, spatio_temporal_factor: float = 0, **kwargs):\n",
    "        super(GeneralizedTemporalSelfAttentionDynamicEdgeConv,\n",
    "              self).__init__(aggr=aggr, flow='target_to_source', **kwargs)\n",
    "\n",
    "        if knn is None:\n",
    "            raise ImportError('`GeneralizedTemporalSelfAttentionDynamicEdgeConv` requires `torch-cluster`.')\n",
    "\n",
    "        self.nn = nn\n",
    "        self.multihead_attn = MultiHeadAttention(attention_in_features, head_num)\n",
    "        self.k = k\n",
    "        self.num_workers = num_workers\n",
    "        self.spatio_temporal_factor = spatio_temporal_factor\n",
    "        self.T = T\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.multihead_attn)\n",
    "        reset(self.nn)\n",
    "\n",
    "    def forward(\n",
    "            self, x,\n",
    "            edge_index,\n",
    "            batch = None ) -> Tensor:\n",
    "        # knn_input = torch.cat((x, sequence_number.reshape(-1, 1)), 1)\n",
    "        # knn_input -= knn_input.min(0, keepdim=True)[0]\n",
    "        # knn_input /= knn_input.max(0, keepdim=True)[0]\n",
    "        # knn_input[:, -1] *= self.spatio_temporal_factor * math.sqrt(x.shape[-1])\n",
    "        # source_data, source_batch, target_data, target_batch, index_mapper = make_proper_data(data=knn_input,\n",
    "        #                                                                                       sequence_number=sequence_number,\n",
    "        #                                                                                       batch=batch,\n",
    "        #                                                                                       self_loop=False,\n",
    "        #                                                                                       T=self.T)\n",
    "        # if isinstance(x, Tensor):\n",
    "        #     x: PairTensor = (x, x)\n",
    "        # assert x[0].dim() == 2, \\\n",
    "        #     'Static graphs not supported in `GeneralizedTemporalSelfAttentionDynamicEdgeConv`.'\n",
    "        # edge_index = knn(target_data, source_data, self.k, target_batch, source_batch,\n",
    "        #                  num_workers=self.num_workers)\n",
    "        # edge_index[1] = index_mapper[edge_index[1]]\n",
    "        return self.propagate(edge_index, x=x, size=None, batch=batch)\n",
    "\n",
    "    def message(self, x_i: Tensor, x_j: Tensor) -> Tensor:\n",
    "        return self.nn(torch.cat([x_i, x_j - x_i], dim=-1))\n",
    "\n",
    "    def aggregate(self, inputs: Tensor, index: Tensor,\n",
    "                  batch: Tensor,\n",
    "                  ptr: Optional[Tensor] = None,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "        original_shape = inputs.shape\n",
    "        # We assume K is fixed and the index tensor is sorted!\n",
    "        attention_input_shape = list([int(original_shape[0] / self.k)]) + list(original_shape)\n",
    "        attention_input_shape[1] = self.k\n",
    "        self_attention_input = inputs.reshape(attention_input_shape)\n",
    "        attn_output = self.multihead_attn(self_attention_input, self_attention_input, self_attention_input)\n",
    "        attn_output = attn_output.reshape(original_shape)\n",
    "        # Apply attention mechanism\n",
    "        return scatter(attn_output, index, dim=self.node_dim, dim_size=dim_size,\n",
    "                       reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(nn={}, k={})'.format(self.__class__.__name__, self.nn,\n",
    "                                        self.k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cb0e6cbedc3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T21:24:46.080602700Z",
     "start_time": "2024-05-16T21:24:46.054605500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, out_channels, graph_convolution_layers=2, T=1, k=4, spatio_temporal_factor=0.01, aggr='max'):\n",
    "        super().__init__()\n",
    "        # self.stn = STN3d()\n",
    "        self.graph_convolution_layers = graph_convolution_layers\n",
    "        \n",
    "        self.gatconv1 = GATConv(5, 64, heads=2, edge_dim = 1)\n",
    "        self.gatconv2 = GATConv(2*64, 64, edge_dim = 1)\n",
    "\n",
    "        # self.conv1 = GeneralizedTemporalSelfAttentionDynamicEdgeConv(nn=MLP([2 * 3, 64, 64, 64]),\n",
    "        #                                                              attention_in_features=64,\n",
    "        #                                                              head_num=8,\n",
    "        #                                                              k=k,\n",
    "        #                                                              spatio_temporal_factor=spatio_temporal_factor,\n",
    "        #                                                              T=T)\n",
    "        # self.conv2 = GeneralizedTemporalSelfAttentionDynamicEdgeConv(nn=MLP([2 * 64, 128]),\n",
    "        #                                                              attention_in_features=128,\n",
    "        #                                                              head_num=8,\n",
    "        #                                                              k=k,\n",
    "        #                                                              spatio_temporal_factor=spatio_temporal_factor,\n",
    "        #                                                              aggr=aggr,\n",
    "        #                                                              T=T)\n",
    "        # self.conv3 = GeneralizedTemporalSelfAttentionDynamicEdgeConv(nn=MLP([2 * 128, 256]),\n",
    "        #                                                              attention_in_features=256,\n",
    "        #                                                              head_num=8,\n",
    "        #                                                              k=k,\n",
    "        #                                                              spatio_temporal_factor=spatio_temporal_factor,\n",
    "        #                                                              aggr=aggr,\n",
    "        #                                                              T=T)\n",
    "        # assert 1 <= graph_convolution_layers <= 3\n",
    "        # if graph_convolution_layers == 3:\n",
    "        #     self.lin1 = MLP([256 + 128 + 64, 1024])\n",
    "        # elif graph_convolution_layers == 2:\n",
    "        #     self.lin1 = MLP([128 + 64, 1024])\n",
    "        # elif graph_convolution_layers == 1:\n",
    "        self.lin1 = MLP([64, 1024])\n",
    "\n",
    "        self.mlp = Seq(\n",
    "            MLP([1024, 512]), Dropout(0.5), MLP([512, 256]), Dropout(0.5),\n",
    "            Lin(256, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        # sequence_numbers, pos, batch = data.x[:, 0].float(), data.pos.float(), data.batch\n",
    "        # pos = pos.reshape(len(torch.unique(data.batch)), -1, 3).transpose(2, 1)\n",
    "        # trans = self.stn(pos)\n",
    "        # pos = pos.transpose(2, 1)\n",
    "        # pos = torch.bmm(pos, trans)\n",
    "        # pos = pos.reshape(-1, 3)\n",
    "        # if self.graph_convolution_layers == 3:\n",
    "        #     x1 = self.conv1(data.x, data.edge_index, data.batch)\n",
    "        #     x2 = self.conv2(x1, data.edge_index, data.batch)\n",
    "        #     x3 = self.conv3(x2, data.edge_index, data.batch)\n",
    "        #     out = self.lin1(torch.cat([x1, x2, x3], dim=1))\n",
    "        # elif self.graph_convolution_layers == 2:\n",
    "        #     x1 = self.conv1(data.x, data.edge_index, data.batch)\n",
    "        #     x2 = self.conv2(x1, data.edge_index, data.batch)\n",
    "        #     out = self.lin1(torch.cat([x1, x2], dim=1))\n",
    "        # else:\n",
    "            # x1 = self.conv1(data.x, data.edge_index, data.batch)\n",
    "        x1 = self.gatconv1(data.x, data.edge_index, edge_attr=data.edge_attr) # adding edge features here!\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = F.dropout(x1, training=self.training)\n",
    "        x1 = self.gatconv2(x1, data.edge_index, edge_attr=data.edge_attr) # edge features here as well\n",
    "        out = self.lin1(x1)\n",
    "        # out = global_max_pool(out, data.batch)\n",
    "        out = self.mlp(out)\n",
    "        out = scatter(out, data.batch, dim=0, reduce='mean')\n",
    "        return F.log_softmax(out, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c31fe069d552c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T22:01:56.623665100Z",
     "start_time": "2024-05-16T21:35:24.941573800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(6, graph_convolution_layers=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "correct = 0\n",
    "count = 0\n",
    "accuracies = []\n",
    "for epoch in range(100):\n",
    "    for train_batch in train_dataloader:\n",
    "        train_batch = train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == train_batch.y).sum()\n",
    "        loss = F.nll_loss(out, train_batch.y)\n",
    "        losses.append(loss.detach())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += len(train_batch)\n",
    "        acc = int(correct) / count\n",
    "        accuracies.append(acc)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [tensor.cpu() for tensor in losses]\n",
    "\n",
    "plt.plot(losses, c=\"blue\")\n",
    "plt.plot(accuracies, c=\"red\")\n",
    "plt.title(\"Loss of the training\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy: \"+str(accuracies[-1]))\n",
    "print(\"Loss: \"+str(losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717b3744a85137a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T22:07:08.001081Z",
     "start_time": "2024-05-16T22:07:04.259077800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_y_pred_label = []\n",
    "total_y_true_label = []\n",
    "correct = 0\n",
    "for test_batch in test_dataloader:\n",
    "    test_batch = test_batch.to(device)\n",
    "    pred = model(test_batch).argmax(dim=1)\n",
    "    total_y_pred_label.extend(pred)\n",
    "    total_y_true_label.extend(test_batch.y)\n",
    "    # print(\"Predicted: \" + str(pred) + \", real: \"+ str(test_batch.y))\n",
    "    correct += (pred == test_batch.y).sum()\n",
    "acc = int(correct) / len(test)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72ae8e67b7bbf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T22:07:08.300076500Z",
     "start_time": "2024-05-16T22:07:08.005080700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SHAPE_NAMES = [0,1,2,3,4,5]\n",
    "total_y_pred = [pred_label.item() for pred_label in total_y_pred_label]\n",
    "total_y_true = [true_label.item() for true_label in total_y_true_label]\n",
    "cm = confusion_matrix(total_y_true, total_y_pred, labels=SHAPE_NAMES)\n",
    "print(cm)\n",
    "# cm = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]) * 100\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = SHAPE_NAMES,\n",
    "              columns = SHAPE_NAMES)\n",
    "plt.figure(figsize = (10,7))\n",
    "plot = sn.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "figure = plot.get_figure()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicated Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fda70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
