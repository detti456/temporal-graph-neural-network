{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from typing import Callable, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import distance as distance_calculator\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import scatter\n",
    "import seaborn as sn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, Dropout, ReLU, BatchNorm1d as BN\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_multi_head_attention import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data\n",
    "In each files, the frame numbers are shifted to come after the largest frame number in the previous file. This way all frame numbers are unique.\n",
    "\n",
    "The dataset contains frames of 1 to 5 people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "column_names=['range','azimuth','doppler','snr','y','x','current_frame','seq']\n",
    "\n",
    "features1: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/1/1/*.csv\")])\n",
    "features1.insert(8, \"Label\", np.zeros(len(features1), dtype=int), True)\n",
    "max_frame = max(features1[\"current_frame\"])\n",
    "\n",
    "features2: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/2/2/*.csv\")])\n",
    "features2.insert(8, \"Label\", np.full(len(features2), 1, dtype=int), True)\n",
    "min_frame = min(features2[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features2[\"current_frame\"] += shift\n",
    "max_frame = max(features2[\"current_frame\"])\n",
    "\n",
    "features3: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/3/3/*.csv\")])\n",
    "features3.insert(8, \"Label\", np.full(len(features3), 2, dtype=int), True)\n",
    "min_frame = min(features3[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features3[\"current_frame\"] += shift\n",
    "max_frame = max(features3[\"current_frame\"])\n",
    "\n",
    "features4: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/4/4/*.csv\")])\n",
    "features4.insert(8, \"Label\", np.full(len(features4), 3, dtype=int), True)\n",
    "min_frame = min(features4[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features4[\"current_frame\"] += shift\n",
    "max_frame = max(features4[\"current_frame\"])\n",
    "\n",
    "features5: DataFrame = pd.concat(\n",
    "    [pd.read_csv(filename, names=column_names, header=None, dtype=float) for filename in glob.glob(\"data/bigger/bigger/*.csv\")])\n",
    "features5.insert(8, \"Label\", np.full(len(features5), 4, dtype=int), True)\n",
    "min_frame = min(features5[\"current_frame\"])\n",
    "shift = max_frame-min_frame+10\n",
    "features5[\"current_frame\"] += shift\n",
    "max_frame = max(features5[\"current_frame\"])\n",
    "\n",
    "all_data = pd.concat([features1, features2, features3, features4, features5])\n",
    "all_data.drop_duplicates(subset=['range','azimuth','doppler','snr','y','x','current_frame','Label'], inplace=True, ignore_index=True)\n",
    "print(\"Number of data points: \"+str(len(all_data)))\n",
    "\n",
    "# group the data by frame numbers\n",
    "all_data_grouped = all_data.groupby(\"current_frame\")\n",
    "print(\"Largest frame number: \"+str(max_frame))\n",
    "print(\"Total number of frames: \"+str(len(all_data_grouped)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_frames(current_frame, previous_frame, k: int, start_index: int):\n",
    "    \"\"\"\n",
    "    Calculates the edges between two frames. \n",
    "    \n",
    "    :param current_frame: The current frame containing parameters to calculate the distance based on \n",
    "    :param previous_frame: The previous frame containing parameters to calculate the distance based on \n",
    "    :param k: The number of nearest neighbours to have in the graph\n",
    "    :param start_index: The index to start labeling the nodes from\n",
    "    :return: The values (distance between points) of the edges and an adjacency list containing the nodes that are connected in the graph. \n",
    "            It also returns a boolean indicating whether the creation was successful or not.\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    adjacency_list = []\n",
    "    previous_nodes = np.arange(len(previous_frame))\n",
    "    for i, point in enumerate(current_frame):\n",
    "        distances = distance_calculator.cdist([point], previous_frame, 'euclidean')[0]\n",
    "        idx = distances.argsort()[::-1]\n",
    "        distances = distances[idx]\n",
    "        previous_nodes = previous_nodes[idx]\n",
    "        if len(distances) < k:\n",
    "            return [], [], False\n",
    "        for j in range(k):\n",
    "            edges.append(distances[j])\n",
    "            adjacency_list.append((i+start_index, previous_nodes[j]+start_index+len(current_frame)))\n",
    "    return edges, adjacency_list, True\n",
    "\n",
    "def create_graph_list_with_overlap(frames:List[DataFrame], k = 3, frame_depth = 2):\n",
    "    \"\"\"\n",
    "    Creates a list of Data objects that represents the graphs build from the input data. \n",
    "    The edges in the graph connects the frames to the previous frame by connecting each \n",
    "    points in a frame to it's nearest neighbour in the previous frame. \n",
    "    The nodes contain information about: doppler, snr, y and x. \n",
    "    The edges store information about the distance between the points (closer points have higher value).\n",
    "    \n",
    "    :param frames: input data grouped and sorted by the frame number\n",
    "    :param k: the number of nearest neighbours to connect each points to\n",
    "    :param frame_depth: the number of frames, one graph should contain\n",
    "    :return: a list of Data objects, containing information about the created graphs\n",
    "    \"\"\"\n",
    "    graphs = []\n",
    "    for i, frame in enumerate(frames[frame_depth:]):\n",
    "        nodes = []\n",
    "        edges = []\n",
    "        adjacency_list = []\n",
    "        relevant_frames = frames[i: i + frame_depth + 1]\n",
    "        point_data = [rf[['doppler','snr','y','x']] for rf in relevant_frames]\n",
    "        time_distance = relevant_frames[-1].iloc[0, 6] - relevant_frames[0].iloc[0, 6]\n",
    "        if time_distance > frame_depth * 2:\n",
    "            continue\n",
    "        point_data_array = [df.to_numpy() for df in point_data]\n",
    "        start_index = 0\n",
    "        for depth in range(frame_depth):\n",
    "            pairwise_edges, pairwise_adjacency_list, success = \\\n",
    "                connect_frames(point_data_array[frame_depth-depth][:,2:], point_data_array[frame_depth-depth-1][:,2:], k, start_index)\n",
    "            if not success:\n",
    "                break\n",
    "            start_index += len(relevant_frames[frame_depth-depth])\n",
    "            edges.extend(pairwise_edges)\n",
    "            adjacency_list.extend(pairwise_adjacency_list)\n",
    "            nodes.extend(point_data_array[frame_depth-depth])\n",
    "        if not success:\n",
    "                continue\n",
    "        nodes.extend(point_data_array[0])\n",
    "        label = frame[\"Label\"].values[0]\n",
    "        \n",
    "        graphs.append(Data(x=torch.tensor(np.array(nodes), dtype=torch.float, device=device), \n",
    "                    edge_index=torch.tensor(np.array(adjacency_list), dtype=torch.int64, device=device).t().contiguous(),\n",
    "                    edge_attr=torch.tensor(np.array(edges), dtype=torch.float, device=device),\n",
    "                    y=torch.tensor(label, dtype=torch.int64, device=device)))\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "frame_depths = [2,4,6,8]\n",
    "ks = [3,5,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating and saving the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.asarray([frame for (_, frame) in all_data_grouped], dtype=\"object\")\n",
    "sorted_data = sorted(data_array,key=lambda x:x[\"current_frame\"].max(axis=0))\n",
    "generated_graphs = []\n",
    "for f in frame_depths:\n",
    "    for k in ks:\n",
    "        graphs = create_graph_list_with_overlap(sorted_data, k=k, frame_depth=f)\n",
    "        print(f\"Number of graphs generated with k = {k} and frame depth = {f}: {len(graphs)}\")\n",
    "        generated_graphs.append(graphs)\n",
    "        torch.save(graphs, f\"data/frame_graphs_k{k}_frame_depth{f}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs generated with k = 3 and frame depth = 2: 16081\n",
      "Number of graphs generated with k = 5 and frame depth = 2: 15697\n",
      "Number of graphs generated with k = 8 and frame depth = 2: 15335\n",
      "Number of graphs generated with k = 3 and frame depth = 4: 11102\n",
      "Number of graphs generated with k = 5 and frame depth = 4: 10788\n",
      "Number of graphs generated with k = 8 and frame depth = 4: 10479\n",
      "Number of graphs generated with k = 3 and frame depth = 6: 6844\n",
      "Number of graphs generated with k = 5 and frame depth = 6: 6633\n",
      "Number of graphs generated with k = 8 and frame depth = 6: 6422\n",
      "Number of graphs generated with k = 3 and frame depth = 8: 3244\n",
      "Number of graphs generated with k = 5 and frame depth = 8: 3123\n",
      "Number of graphs generated with k = 8 and frame depth = 8: 3020\n"
     ]
    }
   ],
   "source": [
    "generated_graphs = []\n",
    "for f in frame_depths:\n",
    "    for k in ks:\n",
    "        graphs = torch.load(f\"data/frame_graphs_k{k}_frame_depth{f}.pt\")\n",
    "        print(f\"Number of graphs generated with k = {k} and frame depth = {f}: {len(graphs)}\")\n",
    "        generated_graphs.append(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test =[]\n",
    "val = []\n",
    "\n",
    "train_dataloaders = []\n",
    "test_dataloaders = []\n",
    "val_dataloaders = []\n",
    "\n",
    "for graphs in generated_graphs:\n",
    "    random.seed(42)\n",
    "    random.shuffle(graphs)\n",
    "\n",
    "    train.append(graphs[:int(0.7 * len(graphs))])\n",
    "    test.append(graphs[int(0.7 * len(graphs)):int(0.85 * len(graphs))])\n",
    "    val.append(graphs[int(0.85 * len(graphs)):])\n",
    "\n",
    "    train_dataloaders.append(DataLoader(train[-1], batch_size=32, shuffle=True, num_workers = 0))\n",
    "    test_dataloaders.append(DataLoader(test[-1], batch_size=32, shuffle=True, num_workers = 0))\n",
    "    val_dataloaders.append(DataLoader(val[-1], batch_size=32, shuffle=True, num_workers = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(channels):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "\n",
    "def reset(nn):\n",
    "    def _reset(item):\n",
    "        if hasattr(item, 'reset_parameters'):\n",
    "            item.reset_parameters()\n",
    "\n",
    "    if nn is not None:\n",
    "        if hasattr(nn, 'children') and len(list(nn.children())) > 0:\n",
    "            for item in nn.children():\n",
    "                _reset(item)\n",
    "        else:\n",
    "            _reset(nn)\n",
    "            \n",
    "class GeneralizedTemporalSelfAttentionDynamicEdgeConv(MessagePassing):\n",
    "    def __init__(self, nn: Callable, \n",
    "                 attention_in_features: int,\n",
    "                 k: int,\n",
    "                 aggr: str = 'mean',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(GeneralizedTemporalSelfAttentionDynamicEdgeConv,\n",
    "              self).__init__(aggr=aggr, flow='source_to_target', **kwargs)\n",
    "\n",
    "        self.nn = nn\n",
    "        self.multihead_attn = MultiHeadAttention(attention_in_features, 8)\n",
    "        self.k = k\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.multihead_attn)\n",
    "        reset(self.nn)\n",
    "\n",
    "    def forward(self, x, data) -> Tensor:\n",
    "        return self.propagate(data.edge_index, x=x, edge_attr=data.edge_attr, size=None, batch=data.batch)\n",
    "\n",
    "    def message(self, x_i: Tensor, x_j: Tensor, edge_attr) -> Tensor:\n",
    "        msg = torch.cat([x_j, x_i - x_j, torch.reshape(edge_attr, (len(edge_attr),1))], dim=-1)\n",
    "        return self.nn(msg)\n",
    "\n",
    "    def aggregate(self, inputs: Tensor, index: Tensor,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "        original_shape = inputs.shape\n",
    "        attention_input_shape = list([int(original_shape[0] / self.k)]) + list(original_shape)\n",
    "        attention_input_shape[1] = self.k\n",
    "        self_attention_input = inputs.reshape(attention_input_shape)\n",
    "        attn_output = self.multihead_attn(self_attention_input, self_attention_input, self_attention_input)\n",
    "        attn_output = attn_output.reshape(original_shape)\n",
    "        # Apply attention mechanism\n",
    "        return scatter(attn_output, index, dim=self.node_dim, dim_size=dim_size,\n",
    "                       reduce=self.aggr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, out_channels, graph_convolution_layers=2, k=3, aggr='mean'):\n",
    "        super().__init__()\n",
    "        self.graph_convolution_layers = graph_convolution_layers\n",
    "\n",
    "        self.conv1 = GeneralizedTemporalSelfAttentionDynamicEdgeConv(nn=MLP([2*4 + 1 , 64, 64, 64]),\n",
    "                                                                     attention_in_features=64, \n",
    "                                                                     k=k, \n",
    "                                                                     aggr=aggr)\n",
    "        \n",
    "        self.conv2 = GeneralizedTemporalSelfAttentionDynamicEdgeConv(nn=MLP([2 * 64 + 1, 128]),\n",
    "                                                                     attention_in_features=128,\n",
    "                                                                     k=k, \n",
    "                                                                     aggr=aggr)\n",
    "\n",
    "        if graph_convolution_layers == 1:\n",
    "            self.lin1 = MLP([64, 1024])\n",
    "        elif graph_convolution_layers == 2:\n",
    "            self.lin1 = MLP([128 + 64, 1024])\n",
    "\n",
    "        self.mlp = Seq(\n",
    "            MLP([1024, 512]), Dropout(0.5), MLP([512, 256]), Dropout(0.5),\n",
    "            Lin(256, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        if self.graph_convolution_layers == 1:\n",
    "            x1 = self.conv1(data.x, data)\n",
    "            out = self.lin1(x1)\n",
    "        elif self.graph_convolution_layers == 2:\n",
    "            x1 = self.conv1(data.x, data)\n",
    "            x2 = self.conv2(x1, data)\n",
    "            out = self.lin1(torch.cat([x1, x2], dim=1))\n",
    "        \n",
    "        out = scatter(src=out, index=data.batch, dim=0, reduce='mean')\n",
    "        out = self.mlp(out)\n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_losses = []\n",
    "model_accuracies = []\n",
    "models = []\n",
    "for i, train_dataloader in enumerate(train_dataloaders):\n",
    "    k = ks[i % len(ks)]\n",
    "    model = Net(5, graph_convolution_layers=1, k=k).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    accuracies = []\n",
    "    for epoch in range(100):\n",
    "        for train_batch in train_dataloader:\n",
    "            train_batch = train_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(train_batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == train_batch.y).sum()\n",
    "            loss = F.nll_loss(out, train_batch.y)\n",
    "            losses.append(loss.detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count += len(train_batch)\n",
    "            acc = int(correct) / count\n",
    "            accuracies.append(acc)\n",
    "        scheduler.step()\n",
    "    \n",
    "    models.append(model)\n",
    "    torch.save(model, f\"data/trained_model_k{k}_frame_depth{frame_depths[int(i/len(ks))]}.pt\")\n",
    "    losses = [tensor.cpu().numpy() for tensor in losses]\n",
    "    model_losses.append(losses)\n",
    "    model_accuracies.append(accuracies)\n",
    "    data = {'Loss': losses,\n",
    "            'Accuracy': accuracies}\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f\"data/training_loss_k{k}_frame_depth{frame_depths[int(i/len(ks))]}.csv\", index=True)\n",
    "    print(f\"trained: {i}\")\n",
    "\n",
    "    plt.plot(losses, c=\"blue\")\n",
    "    plt.plot(accuracies, c=\"red\")\n",
    "    plt.title(f\"Loss of the model with k = {ks[i % len(ks)]} and frame depth = {frame_depths[int(i/len(ks))]}\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training accuracy: \"+str(accuracies[-1]))\n",
    "    print(\"Training loss: \"+str(losses[-1]))\n",
    "    \n",
    "    model.eval()\n",
    "    total_y_pred_label = []\n",
    "    total_y_true_label = []\n",
    "    correct = 0\n",
    "    for val_batch in val_dataloaders[i]:\n",
    "        val_batch = val_batch.to(device)\n",
    "        pred = model(val_batch).argmax(dim=1)\n",
    "        \n",
    "        total_y_pred_label.extend(pred)\n",
    "        total_y_true_label.extend(val_batch.y)\n",
    "        correct += (pred == val_batch.y).sum()\n",
    "    acc = int(correct) / len(val[i])\n",
    "    print(f'Accuracy of the model with k = {ks[i % len(ks)]} and frame depth = {frame_depths[int(i/len(ks))]}: {acc:.4f}')\n",
    "    print(f\"evaluated: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (loss, accuracy) in enumerate(zip(model_losses, model_accuracies)):\n",
    "    plt.plot(loss, c=\"blue\")\n",
    "    plt.plot(accuracy, c=\"red\")\n",
    "    plt.title(f\"Loss of the model with k = {ks[i % len(ks)]} and frame depth = {frame_depths[int(i/len(ks))]}\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Accuracy: \"+str(accuracy[-1]))\n",
    "    print(\"Loss: \"+str(loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracies = []\n",
    "for i, model in enumerate(models):\n",
    "    model.eval()\n",
    "    total_y_pred_label = []\n",
    "    total_y_true_label = []\n",
    "    correct = 0\n",
    "    for val_batch in val_dataloaders[i]:\n",
    "        val_batch = val_batch.to(device)\n",
    "        pred = model(val_batch).argmax(dim=1)\n",
    "        \n",
    "        total_y_pred_label.extend(pred)\n",
    "        total_y_true_label.extend(val_batch.y)\n",
    "        correct += (pred == val_batch.y).sum()\n",
    "    acc = int(correct) / len(val[i])\n",
    "    val_accuracies.append(acc)\n",
    "    print(f'Accuracy of the model with k = {ks[i % len(ks)]} and frame depth = {frame_depths[int(i/len(ks))]}: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_NAMES = [1,2,3,4,5]\n",
    "SHAPE_LABELS = [1,2,3,4,\">4\"]\n",
    "total_y_pred = [pred_label.item() for pred_label in total_y_pred_label]\n",
    "total_y_true = [true_label.item() for true_label in total_y_true_label]\n",
    "cm = confusion_matrix(total_y_true, total_y_pred, labels=SHAPE_NAMES)\n",
    "# print(cm)\n",
    "cm = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]) \n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = SHAPE_LABELS,\n",
    "              columns = SHAPE_LABELS)\n",
    "plt.figure(figsize = (5,4))\n",
    "plot = sn.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "figure = plot.get_figure()\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicated Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"data/trained_model_k3_tesla_no_feature_num_xy_dist_with_distance.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(\"data/trained_model_k3_tesla.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_y_pred_label = []\n",
    "val_y_true_label = []\n",
    "correct = 0\n",
    "for val_batch in val_dataloader:\n",
    "    val_batch = val_batch.to(device)\n",
    "    pred = model(val_batch).argmax(dim=1)\n",
    "    val_y_pred_label.extend(pred)\n",
    "    val_y_true_label.extend(val_batch.y)\n",
    "    correct += (pred == val_batch.y).sum()\n",
    "acc = int(correct) / len(val)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_NAMES = [1,2,3,4,5]\n",
    "SHAPE_LABELS = [1,2,3,4,\">4\"]\n",
    "total_y_pred = [pred_label.item() for pred_label in val_y_pred_label]\n",
    "total_y_true = [true_label.item() for true_label in val_y_true_label]\n",
    "cm = confusion_matrix(total_y_true, total_y_pred, labels=SHAPE_NAMES)\n",
    "# print(cm)\n",
    "cm = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]) \n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = SHAPE_LABELS,\n",
    "              columns = SHAPE_LABELS)\n",
    "plt.figure(figsize = (5,4))\n",
    "plot = sn.heatmap(df_cm, annot=True, cmap='Blues')\n",
    "figure = plot.get_figure()\n",
    "# plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicated Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = np.array([d.y.item() for d in train_frame_graphs])\n",
    "zeros = len(np.where(data_points  == 0)[0])\n",
    "ones = len(np.where(data_points  == 1)[0])\n",
    "twos = len(np.where(data_points  == 2)[0])\n",
    "threes = len(np.where(data_points  == 3)[0]) \n",
    "fours = len(np.where(data_points  == 4)[0])\n",
    "fives = len(np.where(data_points  == 5)[0])\n",
    "\n",
    "labels = [0, 1,2,3,4,5]\n",
    "sample_num = [zeros, ones, twos, threes, fours, fives]\n",
    "p = plt.bar(labels, sample_num)\n",
    "plt.xlabel(\"Number of people\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.bar_label(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = np.array([d.y.item() for d in test_frame_graphs])\n",
    "zeros = len(np.where(data_points  == 0)[0])\n",
    "ones = len(np.where(data_points  == 1)[0])\n",
    "twos = len(np.where(data_points  == 2)[0])\n",
    "threes = len(np.where(data_points  == 3)[0]) \n",
    "fours = len(np.where(data_points  == 4)[0])\n",
    "fives = len(np.where(data_points  == 5)[0])\n",
    "\n",
    "labels = [0, 1,2,3,4,5]\n",
    "sample_num = [zeros, ones, twos, threes, fours, fives]\n",
    "p = plt.bar(labels, sample_num)\n",
    "plt.xlabel(\"Number of people\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.bar_label(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
